{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqEoa0Ho0lnn",
        "outputId": "ccfb9165-b93f-430e-b797-6b72703eabe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-tvm\n",
            "  Downloading apache_tvm-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (24.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (3.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.13.1)\n",
            "Collecting synr==0.6.0 (from apache-tvm)\n",
            "  Downloading synr-0.6.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.12.2)\n",
            "Downloading apache_tvm-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading synr-0.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: synr, apache-tvm\n",
            "Successfully installed apache-tvm-0.11.1 synr-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install apache-tvm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "# 加载预训练的PyTorch模型\n",
        "model = models.mobilenet_v2(pretrained=True)"
      ],
      "metadata": {
        "id": "Qg0G5kU61GVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568f4c41-c15d-4956-acfa-8dc5bd67c348"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 46.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# 定义图像预处理流程\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# 加载并预处理图像\n",
        "img = Image.open('cat.jpg')\n",
        "input_tensor = preprocess(img)\n",
        "input_batch = input_tensor.unsqueeze(0)  # 创建批次维度\n",
        "\n",
        "# 检查是否有可用的GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "input_batch = input_batch.to(device)\n",
        "\n",
        "# 进行前向传播\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "\n",
        "# 获取预测结果\n",
        "_, predicted = torch.max(output, 1)\n",
        "print('预测类别索引:', predicted.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkiewgJOR-vf",
        "outputId": "bd1e29c7-9e7e-488e-edda-43126e4b89a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "预测类别索引: 285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxoptimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q87eaF7L1Z31",
        "outputId": "2815e71e-cd94-44b1-84fa-19a9391402b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxoptimizer\n",
            "  Downloading onnxoptimizer-0.3.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxoptimizer-0.3.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (678 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m678.1/678.1 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, onnxoptimizer\n",
            "Successfully installed onnx-1.17.0 onnxoptimizer-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.onnx\n",
        "\n",
        "# 导出模型到ONNX格式\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "torch.onnx.export(model, dummy_input, \"mobilenetv2.onnx\", verbose=True, export_params=True)"
      ],
      "metadata": {
        "id": "8oVJyU4N1Lrt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm\n",
        "print(tvm.__version__)\n",
        "import onnx\n",
        "\n",
        "# 加载ONNX模型\n",
        "onnx_model = onnx.load(\"mobilenetv2.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4gUvMJs1jlu",
        "outputId": "23368556-73c2-4a68-a7c9-69a8f801340d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm\n",
        "from tvm import relay\n",
        "\n",
        "# 将ONNX模型转换为Relay表示\n",
        "mod, params = relay.frontend.from_onnx(onnx_model)"
      ],
      "metadata": {
        "id": "hKbyysm66uFk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 选择目标平台\n",
        "target = tvm.target.Target(\"llvm\")  # 例如，为CPU编译\n",
        "\n",
        "# 编译模型\n",
        "with tvm.transform.PassContext(opt_level=3):\n",
        "    lib = relay.build(mod, target=target, params=params)\n",
        "    lib.export_library('tvmTest.so')"
      ],
      "metadata": {
        "id": "c4znytoq6vn1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm.runtime\n",
        "module = tvm.runtime.load_module('tvmTest.so')\n"
      ],
      "metadata": {
        "id": "kczKBCh-7v9g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建执行模块\n",
        "ctx = tvm.cpu(0)\n",
        "from tvm.contrib import graph_executor\n",
        "gmod = graph_executor.GraphModule(module['default'](tvm.device('cpu')))\n",
        "\n",
        "# gmod.set_input(\"input.1\", dummy_input.numpy())\n",
        "gmod.set_input(\"input.1\", input_batch.numpy())\n",
        "gmod.run()\n",
        "\n",
        "# 获取输出\n",
        "output_data = gmod.get_output(0)\n",
        "\n",
        "output_data = output_data.asnumpy()\n",
        "\n",
        "import numpy as np\n",
        "# 进行 softmax 以获取概率分布（可选）\n",
        "probabilities = np.exp(output_data) / np.sum(np.exp(output_data), axis=1, keepdims=True)\n",
        "\n",
        "# 获取预测类别索引\n",
        "predicted_class = np.argmax(output_data, axis=1)\n",
        "\n",
        "print('预测类别索引:', predicted_class[0])\n",
        "# print(output_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0dXBAboByMy",
        "outputId": "ae940761-f0ca-429a-f83c-b76a2863a77c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "预测类别索引: 285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItVCf8FeUAZj",
        "outputId": "a422fdf8-d70d-43fa-8103-3c61a8941fa1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat.jpg  mobilenetv2.onnx  sample_data\ttvmTest.so\n"
          ]
        }
      ]
    }
  ]
}