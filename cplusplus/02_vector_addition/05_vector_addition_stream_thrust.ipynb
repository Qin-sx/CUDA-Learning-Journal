{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygz3Nl__OSyU",
        "outputId": "7c6960f6-e1fd-4bf2-f9e1-4cf6950ed044"
      },
      "outputs": [],
      "source": [
        "%%writefile vector_addition_stream_thrust.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <type_traits>\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "\n",
        "#define TYPE int\n",
        "#define N 51200\n",
        "\n",
        "#define nStream 4\n",
        "\n",
        "template <typename T, typename = std::enable_if_t<std::is_arithmetic<T>::value>>\n",
        "__global__ void device_add(T *a, T *b, T *c, int n)\n",
        "{\n",
        "    int id = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (id < n) {\n",
        "        c[id] = a[id] + b[id];\n",
        "    }\n",
        "}\n",
        "\n",
        "template <typename T, typename = std::enable_if_t<std::is_arithmetic<T>::value>>\n",
        "void print_output(T *a, T *b, T *c)\n",
        "{\n",
        "    for (int i = 0; i < N; ++i)\n",
        "    {\n",
        "        printf(\"\\n %d + %d  = %d\", a[i], b[i], c[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int threads_per_block = 0, no_of_blocks = 0;\n",
        "\n",
        "    // Allocate space for host copies of a, b, c and setup input values\n",
        "    using pinned_allocator = thrust::mr::stateless_resource_allocator<TYPE, thrust::system::cuda::universal_host_pinned_memory_resource>;\n",
        "    thrust::host_vector<TYPE, pinned_allocator> a(N);\n",
        "    thrust::host_vector<TYPE, pinned_allocator> b(N);\n",
        "    thrust::host_vector<TYPE, pinned_allocator> c(N);\n",
        "\n",
        "\n",
        "    for (int i = 0; i < N; ++i)\n",
        "    {\n",
        "        a[i] = i;\n",
        "        b[i] = i;\n",
        "    }\n",
        "\n",
        "    // Allocate space for device copies of a, b, c\n",
        "    thrust::device_vector<TYPE> d_a(N);\n",
        "    thrust::device_vector<TYPE> d_b(N);\n",
        "    thrust::device_vector<TYPE> d_c(N);\n",
        "\n",
        "    // Create n streams\n",
        "    cudaStream_t *streams = new cudaStream_t[nStream];\n",
        "    for (int i = 0; i < nStream; ++i)\n",
        "    {\n",
        "        cudaStreamCreate(&streams[i]);\n",
        "    }\n",
        "\n",
        "    // Divide the work between n streams\n",
        "    int partSize = N / nStream;\n",
        "    int parts[nStream * 2];\n",
        "    for (int i = 0; i < nStream; ++i)\n",
        "    {\n",
        "        parts[i * 2] = i * partSize; // Initial index\n",
        "        parts[i * 2 + 1] = (i == nStream - 1) ? (N - (nStream - 1) * partSize) : partSize; // Element number of this part\n",
        "    }\n",
        "\n",
        "    // Copy data from host to device\n",
        "    // for (int i = 0; i < nStream; ++i)\n",
        "    // {\n",
        "    //     cudaMemcpyAsync(thrust::raw_pointer_cast(d_a.data()) + parts[i * 2], a.data().get() + parts[i * 2], parts[i * 2 + 1] * sizeof(TYPE), cudaMemcpyHostToDevice, streams[i]);\n",
        "    //     cudaMemcpyAsync(thrust::raw_pointer_cast(d_b.data()) + parts[i * 2], b.data().get() + parts[i * 2], parts[i * 2 + 1] * sizeof(TYPE), cudaMemcpyHostToDevice, streams[i]);\n",
        "    // }\n",
        "\n",
        "    // Execute kernel\n",
        "    // for (int i = 0; i < nStream; ++i)\n",
        "    // {\n",
        "    //     threads_per_block = 128;\n",
        "    //     no_of_blocks = (parts[i * 2 + 1] + threads_per_block - 1) / threads_per_block;\n",
        "    //     device_add<<<no_of_blocks, threads_per_block, 0, streams[i]>>>(\n",
        "    //         thrust::raw_pointer_cast(d_a.data()) + parts[i * 2],\n",
        "    //         thrust::raw_pointer_cast(d_b.data()) + parts[i * 2],\n",
        "    //         thrust::raw_pointer_cast(d_c.data()) + parts[i * 2],\n",
        "    //         parts[i * 2 + 1]);\n",
        "    // }\n",
        "\n",
        "    // Copy result back to host\n",
        "    // for (int i = 0; i < nStream; ++i)\n",
        "    // {\n",
        "    //     cudaMemcpyAsync(c.data().get() + parts[i * 2], thrust::raw_pointer_cast(d_c.data()) + parts[i * 2], parts[i * 2 + 1] * sizeof(TYPE), cudaMemcpyDeviceToHost, streams[i]);\n",
        "    // }\n",
        "\n",
        "    // Another way to achieve the overlapping\n",
        "    for (int i = 0; i < nStream; ++i)\n",
        "    {\n",
        "        cudaMemcpyAsync(thrust::raw_pointer_cast(d_a.data()) + parts[i * 2], a.data().get() + parts[i * 2], parts[i * 2 + 1] * sizeof(TYPE), cudaMemcpyHostToDevice, streams[i]);\n",
        "        cudaMemcpyAsync(thrust::raw_pointer_cast(d_b.data()) + parts[i * 2], b.data().get() + parts[i * 2], parts[i * 2 + 1] * sizeof(TYPE), cudaMemcpyHostToDevice, streams[i]);\n",
        "\n",
        "        threads_per_block = 128;\n",
        "        no_of_blocks = (parts[i * 2 + 1] + threads_per_block - 1) / threads_per_block;\n",
        "\n",
        "        device_add<<<no_of_blocks, threads_per_block, 0, streams[i]>>>(\n",
        "            thrust::raw_pointer_cast(d_a.data()) + parts[i * 2],\n",
        "            thrust::raw_pointer_cast(d_b.data()) + parts[i * 2],\n",
        "            thrust::raw_pointer_cast(d_c.data()) + parts[i * 2],\n",
        "            parts[i * 2 + 1]);\n",
        "\n",
        "        cudaMemcpyAsync(c.data().get() + parts[i * 2], thrust::raw_pointer_cast(d_c.data()) + parts[i * 2], parts[i * 2 + 1] * sizeof(TYPE), cudaMemcpyDeviceToHost, streams[i]);\n",
        "    }\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    //  print_output(a.data().get(), b.data().get(), c.data().get());\n",
        "\n",
        "    // Clean up\n",
        "    for (int i = 0; i < nStream; ++i)\n",
        "    {\n",
        "        cudaStreamDestroy(streams[i]);\n",
        "    }\n",
        "    delete[] streams;\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qv7bTw-DPGLV"
      },
      "outputs": [],
      "source": [
        "!nvcc -o vector_addition_stream_thrust vector_addition_stream_thrust.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fG-YSbFsVqd9"
      },
      "outputs": [],
      "source": [
        "!./vector_addition_stream_thrust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytMsrP1LZaFO",
        "outputId": "51651fa8-ffe2-42ee-eb88-a74020396023"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXL3-e9wZgd-",
        "outputId": "f200487b-d5d4-4188-807c-83065e0d6f28"
      },
      "outputs": [],
      "source": [
        "!apt update\n",
        "!apt install ./drive/MyDrive/Nsight/nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
        "!apt --fix-broken install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DiilafsaBqJ",
        "outputId": "8750db7a-d2b8-42ac-ca11-a48e7efa03de"
      },
      "outputs": [],
      "source": [
        "!nsys profile -o report_vector_addition_stream_thrust ./vector_addition_stream_thrust"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
