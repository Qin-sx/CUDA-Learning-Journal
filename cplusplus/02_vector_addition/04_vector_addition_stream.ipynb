{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNxg4t65KZ-E"
      },
      "source": [
        "More information on this link https://developer.nvidia.com/blog/how-overlap-data-transfers-cuda-cc/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCpjNyLkKxYT",
        "outputId": "eefa2b4f-e914-4636-8e28-75666c793303"
      },
      "outputs": [],
      "source": [
        "%%writefile vector_addition_stream.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <type_traits>\n",
        "\n",
        "#define TYPE int\n",
        "#define N 51200\n",
        "\n",
        "#define nStream 4\n",
        "\n",
        "template <typename T, typename = std::enable_if_t<std::is_arithmetic<T>::value>>\n",
        "__global__ void device_add(T *a, T *b, T *c, int n)\n",
        "{\n",
        "    int id = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (id < n) {\n",
        "        c[id] = a[id] + b[id];\n",
        "    }\n",
        "}\n",
        "\n",
        "template <typename T, typename = std::enable_if_t<std::is_arithmetic<T>::value>>\n",
        "void print_output(T *a, T *b, T *c)\n",
        "{\n",
        "    for (int i = 0; i < N; ++i)\n",
        "    {\n",
        "        printf(\"\\n %d + %d  = %d\", a[i], b[i], c[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    TYPE *a, *b, *c;\n",
        "    TYPE *d_a, *d_b, *d_c;\n",
        "    int threads_per_block = 0, no_of_blocks = 0;\n",
        "\n",
        "    int size = N * sizeof(TYPE);\n",
        "\n",
        "    // Allocate space for host copies of a, b, c and setup input values\n",
        "    cudaHostAlloc(&a, size, cudaHostAllocDefault);\n",
        "    cudaHostAlloc(&b, size, cudaHostAllocDefault);\n",
        "    cudaHostAlloc(&c, size, cudaHostAllocDefault);\n",
        "\n",
        "    for (int i = 0; i < N; ++i)\n",
        "    {\n",
        "        a[i] = i;\n",
        "        b[i] = i;\n",
        "    }\n",
        "\n",
        "    // Allocate space for device copies of a, b, c\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Create n streams\n",
        "    cudaStream_t *streams = new cudaStream_t[nStream];\n",
        "    for (int i = 0; i < nStream; ++i)\n",
        "    {\n",
        "        cudaStreamCreate(&streams[i]);\n",
        "    }\n",
        "\n",
        "    // Divide the work between n streams\n",
        "    int partSize = N / nStream;\n",
        "    int parts[nStream * 2];\n",
        "    for (int i = 0; i < nStream; ++i)\n",
        "    {\n",
        "        parts[i * 2] = i * partSize; // Initial index\n",
        "        parts[i * 2 + 1] = (i == nStream - 1) ? (N - (nStream - 1) * partSize) : partSize; // Element number of this part\n",
        "    }\n",
        "\n",
        "    // Copy data from host to device\n",
        "    for (int i = 0; i < nStream; ++i)\n",
        "    {\n",
        "        cudaMemcpyAsync(d_a + parts[i * 2], a + parts[i * 2], parts[i * 2 + 1] * sizeof(TYPE), cudaMemcpyHostToDevice, streams[i]);\n",
        "        cudaMemcpyAsync(d_b + parts[i * 2], b + parts[i * 2], parts[i * 2 + 1] * sizeof(TYPE), cudaMemcpyHostToDevice, streams[i]);\n",
        "    }\n",
        "\n",
        "    // Execute kernel\n",
        "    for (int i = 0; i < nStream; ++i)\n",
        "    {\n",
        "        threads_per_block = 128;\n",
        "        no_of_blocks = (parts[i * 2 + 1] + threads_per_block - 1) / threads_per_block;\n",
        "        device_add<<<no_of_blocks, threads_per_block, 0, streams[i]>>>(\n",
        "            d_a + parts[i * 2], d_b + parts[i * 2], d_c + parts[i * 2], parts[i * 2 + 1]);\n",
        "    }\n",
        "\n",
        "    // Copy result back to host\n",
        "    for (int i = 0; i < nStream; ++i)\n",
        "    {\n",
        "        cudaMemcpyAsync(c + parts[i * 2], d_c + parts[i * 2], parts[i * 2 + 1] * sizeof(TYPE), cudaMemcpyDeviceToHost, streams[i]);\n",
        "    }\n",
        "\n",
        "    // Another way to achieve the overlapping\n",
        "    //  for (int i = 0; i < nStream; ++i)\n",
        "    //  {\n",
        "    //      cudaMemcpyAsync(d_a + parts[i * 2], a + parts[i * 2], parts[i * 2 + 1] * sizeof(TYPE), cudaMemcpyHostToDevice, streams[i]);\n",
        "    //      cudaMemcpyAsync(d_b + parts[i * 2], b + parts[i * 2], parts[i * 2 + 1] * sizeof(TYPE), cudaMemcpyHostToDevice, streams[i]);\n",
        "    //      threads_per_block = 128;\n",
        "    //      no_of_blocks = (parts[i * 2 + 1] + threads_per_block - 1) / threads_per_block;\n",
        "    //\n",
        "    //      device_add<<<no_of_blocks, threads_per_block, 0, streams[i]>>>(\n",
        "    //          d_a + parts[i * 2], d_b + parts[i * 2], d_c + parts[i * 2], parts[i * 2 + 1]);\n",
        "    //      cudaMemcpyAsync(c + parts[i * 2], d_c + parts[i * 2], parts[i * 2 + 1] * sizeof(TYPE), cudaMemcpyDeviceToHost, streams[i]);\n",
        "    //  }\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // print_output(a, b, c);\n",
        "\n",
        "    // Clean up\n",
        "    for (int i = 0; i < nStream; ++i)\n",
        "    {\n",
        "        cudaStreamDestroy(streams[i]);\n",
        "    }\n",
        "    delete[] streams;\n",
        "    cudaFreeHost(a);\n",
        "    cudaFreeHost(b);\n",
        "    cudaFreeHost(c);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2Qixk1RaK8L4"
      },
      "outputs": [],
      "source": [
        "!nvcc -o vector_addition_stream vector_addition_stream.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ih9yvvXRLukR"
      },
      "outputs": [],
      "source": [
        "!./vector_addition_stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAKpGOp63EP6",
        "outputId": "430dfb93-df9b-4dd1-9f04-bbfe3ba1e9a7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wsctFwl4Y7_",
        "outputId": "71be1a5a-5737-4d77-c7a1-07afd29acfd1"
      },
      "outputs": [],
      "source": [
        "!apt update\n",
        "!apt install ./drive/MyDrive/Nsight/nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
        "!apt --fix-broken install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGnFu-Wm4ehR",
        "outputId": "4d03ee73-8048-4996-de6c-87fc7f9d5b09"
      },
      "outputs": [],
      "source": [
        "!nsys profile -o report_vector_addition_stream ./vector_addition_stream"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
