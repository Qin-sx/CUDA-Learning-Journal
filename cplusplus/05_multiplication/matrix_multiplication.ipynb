{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "Reference: https://zhuanlan.zhihu.com/p/410278370"
      ],
      "metadata": {
        "id": "b1mXh7LpHFhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_multiplication.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <type_traits>\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/sequence.h>\n",
        "\n",
        "#define TYPE int\n",
        "#define M 4\n",
        "#define K 3\n",
        "#define N 2\n",
        "#define BLOCK_SIZE 32\n",
        "#define NUM_PER_THREAD 8\n",
        "\n",
        "// M 4 K 3\n",
        "//  1  2  3\n",
        "//  4  5  6\n",
        "//  7  8  9\n",
        "// 10 11 12\n",
        "\n",
        "// K 3 N 2\n",
        "// 1 4\n",
        "// 2 5\n",
        "// 3 6\n",
        "\n",
        "// M 4 N 2\n",
        "// 1*1 + 2*2 + 3*3 = 14         1*4 + 2*5 + 3*6 = 32\n",
        "// 4*1 + 5*2 + 6*3 = 32         4*4 + 5*5 + 6*6 = 77\n",
        "// 7*1 + 8*2 + 9*3 = 50         7*4 + 8*5 + 9*6 = 122\n",
        "// 10*1 + 11*2 + 12*3 = 68      10*4 + 11*5 + 12*6 = 167\n",
        "//  x  x\n",
        "//y\n",
        "//y\n",
        "//y\n",
        "//y\n",
        "\n",
        "__global__ void warm_up()\n",
        "{\n",
        "    int indexX = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int indexY = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    if (indexX < M && indexY < N)\n",
        "    {\n",
        "        float a = 0.0f;\n",
        "        float b = 1.0f;\n",
        "        float c = a + b;\n",
        "    }\n",
        "}\n",
        "\n",
        "template <typename T, typename = std::enable_if_t<std::is_arithmetic<T>::value>>\n",
        "__global__ void matrix_multiplication(const T *a, const T *b, T *c) {\n",
        "    int indexX = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int indexY = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    if(indexY < M && indexX < N) {\n",
        "        T cTmp = 0;\n",
        "        for(int i = 0; i < K; ++i){\n",
        "            cTmp += a[indexY * K + i] * b[i * N + indexX];\n",
        "        }\n",
        "        c[indexY * N + indexX] = cTmp;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "template <typename T, typename = std::enable_if_t<std::is_arithmetic<T>::value>>\n",
        "void print_output(T *a, T *b, T* c)\n",
        "{\n",
        "    for (int i = 0; i < M * K; ++i)\n",
        "    {\n",
        "        if (i % K == 0)\n",
        "        {\n",
        "            std::cout << std::endl;\n",
        "        }\n",
        "        std::cout << a[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "    for (int i = 0; i < K * N; ++i)\n",
        "    {\n",
        "        if (i % N == 0)\n",
        "        {\n",
        "            std::cout << std::endl;\n",
        "        }\n",
        "        std::cout << b[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "    for (int i = 0; i < M * N; ++i)\n",
        "    {\n",
        "        if (i % N == 0)\n",
        "        {\n",
        "            std::cout << std::endl;\n",
        "        }\n",
        "        std::cout << c[i] << \" \";\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    // Allocate space for host copies of a, b\n",
        "    thrust::host_vector<TYPE> a(M * K);\n",
        "    thrust::host_vector<TYPE> b(K * N);\n",
        "    thrust::host_vector<TYPE> c(M * N);\n",
        "\n",
        "    // Allocate space for device copies of a, b\n",
        "    thrust::device_vector<TYPE> d_a(M * K, 1);\n",
        "    thrust::device_vector<TYPE> d_b(K * N, 1);\n",
        "    thrust::device_vector<TYPE> d_c(M * N, 0);\n",
        "\n",
        "    dim3 threads_per_block(BLOCK_SIZE, BLOCK_SIZE, 1);\n",
        "    dim3 no_of_blocks((N + BLOCK_SIZE - 1) / BLOCK_SIZE, (M + BLOCK_SIZE - 1) / BLOCK_SIZE, 1);\n",
        "\n",
        "    warm_up<<<no_of_blocks, threads_per_block>>>();\n",
        "    matrix_multiplication<<<no_of_blocks, threads_per_block>>>(thrust::raw_pointer_cast(d_a.data()), thrust::raw_pointer_cast(d_b.data()), thrust::raw_pointer_cast(d_c.data()));\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    thrust::copy(d_a.begin(), d_a.end(), a.begin());\n",
        "    thrust::copy(d_b.begin(), d_b.end(), b.begin());\n",
        "    thrust::copy(d_c.begin(), d_c.end(), c.begin());\n",
        "\n",
        "    print_output(a.data(), b.data(), c.data());\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "wqOmfUicGKe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o matrix_multiplication -lineinfo matrix_multiplication.cu"
      ],
      "metadata": {
        "id": "Et2ZK7-irqCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_multiplication"
      ],
      "metadata": {
        "id": "-_AsLSCErvV9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
