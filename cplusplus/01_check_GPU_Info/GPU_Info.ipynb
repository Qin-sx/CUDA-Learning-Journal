{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hx_WEN2HW7X"
      },
      "source": [
        "It will show CUDA version, if GPU platform is chosen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkO3czB0HO3b",
        "outputId": "71469b40-0fa4-441b-ca80-b09548f0707e"
      },
      "outputs": [],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOMzEn-NJbAf"
      },
      "source": [
        "Write a program for printing GPU info (generated kimi) into a .cu file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8T9zNx46PyK",
        "outputId": "401c1612-417c-4a39-82e5-a1ff5143e9c6"
      },
      "outputs": [],
      "source": [
        "%%writefile GPU_Info.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "int main() {\n",
        "    int deviceCount = 0;\n",
        "    cudaError_t error_id = cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "    if (error_id == cudaSuccess) {\n",
        "        std::cout << \"Detected \" << deviceCount << \" CUDA Capable GPU(s)\\n\";\n",
        "    } else {\n",
        "        std::cerr << \"cudaGetDeviceCount returned \" << cudaGetErrorString(error_id)\n",
        "                  << \" (\" << error_id << \")\\n\";\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < deviceCount; ++i) {\n",
        "        cudaDeviceProp prop;\n",
        "        error_id = cudaGetDeviceProperties(&prop, i);\n",
        "\n",
        "        if (error_id == cudaSuccess) {\n",
        "            std::cout << \"Device \" << i << \":\\n\";\n",
        "            std::cout << \"  Name: \" << prop.name << \"\\n\";\n",
        "            std::cout << \"  Compute Capability: \" << prop.major << \".\" << prop.minor << \"\\n\";\n",
        "            std::cout << \"  Total Global Memory: \" << prop.totalGlobalMem << \" bytes (\" << prop.totalGlobalMem/(1024.0*1024.0*1024.0) << \"GB)\\n\";\n",
        "            std::cout << \"  Clock Rate: \" << prop.clockRate << \" kHz\\n\";\n",
        "            std::cout << \"  Memory Clock Rate: \" << prop.memoryClockRate << \" kHz\\n\";\n",
        "            std::cout << \"  Memory Bus Width: \" << prop.memoryBusWidth << \" bits\\n\";\n",
        "            std::cout << \"  L2 Cache Size: \" << prop.l2CacheSize << \" bytes (\" << prop.l2CacheSize/(1024.0*1024.0) << \"MB)\\n\";\n",
        "            std::cout << \"  Multiprocessor Count: \" << prop.multiProcessorCount << \"\\n\";\n",
        "            std::cout << \"  Max Threads Per Multiprocessor: \" << prop.maxThreadsPerMultiProcessor << \"\\n\";\n",
        "            std::cout << \"  Max Threads Per Block: \" << prop.maxThreadsPerBlock << \"\\n\";\n",
        "            std::cout << \"  Max Blocks Per Multiprocessor: \" << prop.maxBlocksPerMultiProcessor << \"\\n\";\n",
        "            std::cout << \"  Max Grid Size (x): \" << prop.maxGridSize[0] << \"\\n\";\n",
        "            std::cout << \"  Max Grid Size (y): \" << prop.maxGridSize[1] << \"\\n\";\n",
        "            std::cout << \"  Max Grid Size (z): \" << prop.maxGridSize[2] << \"\\n\";\n",
        "        } else {\n",
        "            std::cerr << \"cudaGetDeviceProperties returned \" << cudaGetErrorString(error_id)\n",
        "                      << \" (\" << error_id << \")\\n\";\n",
        "            return -1;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w8OQ8IaJo1r"
      },
      "source": [
        "Compile and run the GPU_Info file that was created in the previous cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8maGj8fBKFj2"
      },
      "outputs": [],
      "source": [
        "!nvcc -o GPU_Info GPU_Info.cu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyFon886Mcka",
        "outputId": "b02a49b8-6597-43e7-8c96-d72cc46b9500"
      },
      "outputs": [],
      "source": [
        "!./GPU_Info"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
